import os
import pandas as pd
from collections import Counter
from tqdm.auto import tqdm
from joblib import Parallel, delayed

tqdm.pandas()

# df = pd.DataFrame({
#     'PID': [...],
#     'title': [...],
#     'paragraph_index': [...],
#     'paragraph_pos': [[('í˜•íƒœì†Œ1', 'NNG'), ('í˜•íƒœì†Œ2', 'JKS'), ...], ...],
#     'generated': [...]
# })


def get_pos_ratio(pos_list, target_tags):
    # í’ˆì‚¬ë³„ ë¹„ìœ¨
    total = len(pos_list)
    if total == 0:
        return {tag: 0.0 for tag in target_tags}
    counter = Counter(tag for _, tag in pos_list)
    return {tag: counter.get(tag, 0) / total for tag in target_tags}

def get_special_pos_ratio(pos_list, special_tags=['NNP', 'SL']):
    # ê³ ìœ  ëª…ì‚¬(NNP), ì™¸ë˜ì–´(SL) ë¹„ìœ¨
    total = len(pos_list)
    if total == 0:
        return {tag: 0.0 for tag in special_tags}
    counter = Counter(tag for _, tag in pos_list)
    return {tag: counter.get(tag, 0) / total for tag in special_tags}

def get_josa_eomi_variety(pos_list):
    # ì¡°ì‚¬/ì–´ë¯¸ ë‹¤ì–‘ì„± (ì¢…ë¥˜ ìˆ˜)
    josa_tags = {'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC'}
    eomi_tags = {'EF', 'EC', 'ETN', 'ETM', 'EP'}
    josa_set = set(tag for _, tag in pos_list if tag in josa_tags)
    eomi_set = set(tag for _, tag in pos_list if tag in eomi_tags)
    return {'josa_variety': len(josa_set), 'eomi_variety': len(eomi_set)}

def get_josa_eomi_repeat(pos_list):
    # ì¡°ì‚¬/ì–´ë¯¸ì˜ ë°˜ë³µ íŒ¨í„´ (ë™ì¼ ì¡°ì‚¬/ì–´ë¯¸ ì—°ì† ì‚¬ìš© ë¹ˆë„)
    josa_tags = {'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC'}
    eomi_tags = {'EF', 'EC', 'ETN', 'ETM', 'EP'}
    prev_josa = None
    prev_eomi = None
    josa_repeat = 0
    eomi_repeat = 0
    for _, tag in pos_list:
        if tag in josa_tags:
            if tag == prev_josa:
                josa_repeat += 1
            prev_josa = tag
        else:
            prev_josa = None
        if tag in eomi_tags:
            if tag == prev_eomi:
                eomi_repeat += 1
            prev_eomi = tag
        else:
            prev_eomi = None
    return {'josa_repeat': josa_repeat, 'eomi_repeat': eomi_repeat}

def get_pos_type_variety(pos_list):
    # í˜•íƒœì†Œ ìœ í˜• ë‹¤ì–‘ì„± (ìœ ë‹ˆí¬ íƒœê·¸ ê°œìˆ˜)
    tag_set = set(tag for _, tag in pos_list)
    return {'pos_type_variety': len(tag_set)}

def extract_features_from_paragraph(paragraph_pos):
    features = {}
    main_tags = ['NNG', 'VV', 'JKS', 'JKO', 'EF', 'EC']
    features.update(get_pos_ratio(paragraph_pos, main_tags))
    features.update(get_special_pos_ratio(paragraph_pos))
    features.update(get_josa_eomi_variety(paragraph_pos))
    features.update(get_josa_eomi_repeat(paragraph_pos))
    features.update(get_pos_type_variety(paragraph_pos))
    return features

# --- ë³‘ë ¬ ì²˜ë¦¬ & ì§„í–‰ìƒí™© í‘œì‹œ ---
def add_features_to_df(df, n_jobs=4):
    results = Parallel(n_jobs=n_jobs)(
        delayed(extract_features_from_paragraph)(row) for row in tqdm(df['paragraph_pos'], desc="Feature Extraction")
    )
    feature_df = pd.DataFrame(results, index=df.index) 
    return pd.concat([df, feature_df], axis=1)

def main(prefix, input_dir, idx, output_dir, n_jobs=4):
    data_path=f"../../data/{prefix}_{input_dir}"
    file_name=f"{prefix}_paragraph_pos_{idx}.pkl"
    input_full_name=os.path.join(data_path, file_name)
    
    if not os.path.exists(input_full_name):
        print(f"íŒŒì¼ âŒ: {input_full_name}")
        return
    
    df=pd.read_pickle(input_full_name)
    print(f"{file_name} data points: {len(df)} ê°œ")

    df = add_features_to_df(df, n_jobs=n_jobs)

    output_path=f"../../data/{prefix}_{output_dir}"
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    output_full_name=os.path.join(output_path, file_name)
    df.to_pickle(output_full_name)
    print(f"[Saved] {output_full_name} ì €ì¥ ì™„ë£Œ ğŸ—‚ï¸")
    print(f"{file_name} data points: {len(df)} ê°œ")

if __name__=="__main__":
    import argparse
    parser = argparse.ArgumentParser(description="í˜• ë³€í™˜")
    parser.add_argument('--prefix', type=str, default="train")
    parser.add_argument('--input_dir', type=str, default="paragraph_pos")
    parser.add_argument('--idx', type=int, required=True)
    parser.add_argument('--output_dir', type=str, default='paragraph_pos_stats')
    parser.add_argument('--n_jobs', type=int, default=4, help='ë³‘ë ¬ ì²˜ë¦¬ ì½”ì–´ ìˆ˜')
    args = parser.parse_args()

    main(prefix=args.prefix, 
         input_dir=args.input_dir, 
         idx=args.idx, 
         output_dir=args.output_dir,
         n_jobs=args.n_jobs)
