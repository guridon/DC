{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b493449",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"../../data/paragraph_pos\"\n",
    "pkl_files = [fname for fname in os.listdir(output_dir) if fname.startswith(\"train_paragraph_pos_\") and fname.endswith(\".pkl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_files = sorted([fname for fname in os.listdir(output_dir) if fname.startswith(\"paragraph_pos_\") and fname.endswith(\".pkl\")])\n",
    "print(pkl_files)\n",
    "dfs = []\n",
    "for fname in tqdm(pkl_files, desc=\"paragraph_pos_idx.pkl 병합: \"):\n",
    "    df = pd.read_pickle(os.path.join(output_dir, fname))\n",
    "    dfs.append(df)\n",
    "all_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee27c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paragraph_id = pd.read_csv(\"../../data/train_paragraph_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (title, paragraph_index) <-> paragraph_pos 매핑\n",
    "key_to_pos = {\n",
    "    (row['title'], row['paragraph_index']): row['paragraph_pos']\n",
    "    for _, row in tqdm(all_df.iterrows(), total=len(all_df))\n",
    "}\n",
    "tqdm.pandas(desc=\"paragraph_pos 매핑\")\n",
    "train_paragraph_id['paragraph_pos'] = train_paragraph_id.progress_apply(\n",
    "    lambda row: key_to_pos.get((row['title'], row['paragraph_index']), None), axis=1\n",
    ")\n",
    "final_df = train_paragraph_id.sort_values('ID')[['ID', 'title', 'paragraph_index',\n",
    "                                                 'paragraph_pos', 'generated']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662202c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2345ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = final_df['title'].unique()\n",
    "n_files = 6\n",
    "titles_per_file = ceil(len(titles) / n_files)\n",
    "title_groups = [titles[i*titles_per_file:(i+1)*titles_per_file] for i in range(n_files)]\n",
    "\n",
    "output_dir = \"../../data/train_id_paragraph_pos\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, title_group in tqdm(enumerate(title_groups), total=n_files):\n",
    "    chunk = final_df[final_df['title'].isin(title_group)]\n",
    "    chunk = chunk.sort_values('ID')\n",
    "    chunk.to_pickle(os.path.join(output_dir, f\"train_paragraph_pos_{i}.pkl\"))\n",
    "    print(f\"Saved: train_paragraph_pos_{i}.pkl with {len(chunk)} rows, titles: {len(title_group)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
